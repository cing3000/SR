{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRGAN\n",
    "\n",
    "Original paper is here:\n",
    "[Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network](https://arxiv.org/abs/1609.04802)\n",
    "\n",
    "Architecture\n",
    "![SRGAN Architecture](srgan-model.jpeg)\n",
    "\n",
    "\n",
    "A keras implementation of SRGAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, glob, gc\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from tensorflow.python.keras.utils.generic_utils import Progbar\n",
    "\n",
    "from models.srgan import SRGAN\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_height = 24\n",
    "lr_width = 24\n",
    "upscaling_rate = 8\n",
    "\n",
    "pack_size = 2000\n",
    "batch_size = 4\n",
    "lr_init = 1e-4\n",
    "\n",
    "# initialize G\n",
    "num_epoch_init_g = 100\n",
    "\n",
    "# adversarial learning\n",
    "steps_per_epoch = 5000\n",
    "num_epoch_gan = 20\n",
    "checkpoint_step = 10\n",
    "#n_epoch = 2000\n",
    "#lr_decay = 0.1\n",
    "#decay_step = int(n_epoch/2)\n",
    "\n",
    "verbose_interval = 1\n",
    "\n",
    "# image paths\n",
    "train_hr_img_path = 'datasets/DIV2K/DIV2K_train_HR'\n",
    "train_lr_img_path = 'datasets/DIV2K/DIV2K_train_LR'\n",
    "\n",
    "valid_hr_img_path = 'datasets/DIV2K/DIV2K_valid_HR'\n",
    "valid_lr_img_path = 'datasets/DIV2K/DIV2K_valid_LR'\n",
    "\n",
    "# checkpoints and saved model\n",
    "checkpoint_dir = 'checkpoints/srgan/'\n",
    "sample_dir = 'samples/srgan/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(hr_img_path, lr_img_path, output_file):\n",
    "    \n",
    "    hr_file_list = np.array(tl.files.load_file_list(path=hr_img_path, regx='.*.png', printable=False))\n",
    "    np.random.shuffle(hr_file_list)\n",
    "\n",
    "    r = upscaling_rate\n",
    "    HR = []\n",
    "    LR = []\n",
    "    \n",
    "    load_prog = Progbar(hr_file_list.shape[0])\n",
    "    prog = 0\n",
    "    n = 0\n",
    "    \n",
    "    for hr_img_file in hr_file_list:\n",
    "\n",
    "        file_name, file_ext = hr_img_file.split('.')\n",
    "        hr_file = os.path.join(hr_img_path, hr_img_file)\n",
    "        lr_file = os.path.join(lr_img_path, file_name + \"x4.\" + file_ext)\n",
    "        \n",
    "        hr_img = plt.imread(hr_file)\n",
    "        lr_img = plt.imread(lr_file)\n",
    "        \n",
    "        lr_shape = lr_img.shape\n",
    "\n",
    "        for y in range(0, lr_shape[0]-lr_height+1, lr_height):\n",
    "            y_end = y+lr_height\n",
    "            for x in range(0, lr_shape[1]-lr_width+1, lr_width):\n",
    "                x_end = x+lr_width\n",
    "                \n",
    "                lr_data = lr_img[y:y_end, x:x_end, :]\n",
    "                hr_data = hr_img[y*r:y_end*r, x*r:x_end*r, :]\n",
    "\n",
    "                HR.append(hr_data)\n",
    "                LR.append(lr_data)\n",
    "\n",
    "        if len(HR) > pack_size:\n",
    "\n",
    "            hr_buf = np.array(HR)\n",
    "            lr_buf = np.array(LR)    \n",
    "            indices = np.arange(pack_size)\n",
    "            np.random.shuffle(indices)\n",
    "            hr_pack = hr_buf[indices]\n",
    "            lr_pack = lr_buf[indices]\n",
    "            \n",
    "            # Save pack\n",
    "            filename = \"%s_%d.hdf5\" % (output_file, n)\n",
    "            hf = h5py.File(filename, 'w')\n",
    "            hf.create_dataset('hr', data=hr_pack)\n",
    "            hf.create_dataset('lr', data=lr_pack)\n",
    "            hf.close()\n",
    "            #print(\"%s saved\" % filename)\n",
    "            \n",
    "            # Remove saved data\n",
    "            HR = HR[pack_size:]\n",
    "            LR = LR[pack_size:]\n",
    "            \n",
    "            n += 1\n",
    "            \n",
    "        prog += 1\n",
    "        load_prog.update(prog)\n",
    "\n",
    "\n",
    "def data_generator(file_list, train=True):\n",
    "    \n",
    "    while True:\n",
    "        for file in file_list:\n",
    "            hf = h5py.File(file, 'r')\n",
    "            pack_hr = np.array(hf.get('hr'))\n",
    "            pack_lr = np.array(hf.get('lr'))\n",
    "\n",
    "            num_in_pack = pack_hr.shape[0]\n",
    "\n",
    "            for i in range(num_in_pack//batch_size):\n",
    "                batch_hr = pack_hr[i*batch_size:(i+1)*batch_size]\n",
    "                batch_lr = pack_lr[i*batch_size:(i+1)*batch_size]\n",
    "                yield (batch_lr, batch_hr)\n",
    "            hf.close()\n",
    "\n",
    "if not os.path.isfile(os.path.join(checkpoint_dir, \"train_0.hdf5\")):\n",
    "    print(\"Pre-processing training data...\")\n",
    "    prepare_data(train_hr_img_path, train_lr_img_path, os.path.join(checkpoint_dir, \"train\"))\n",
    "    \n",
    "if not os.path.isfile(os.path.join(checkpoint_dir, \"valid_0.hdf5\")):\n",
    "    print(\"Pre-processing validation data...\")\n",
    "    prepare_data(valid_hr_img_path, valid_lr_img_path, os.path.join(checkpoint_dir, \"valid\"))\n",
    "\n",
    "train_files = glob.glob(os.path.join(checkpoint_dir, \"train_*.hdf5\"))\n",
    "valid_files = glob.glob(os.path.join(checkpoint_dir, \"valid_*.hdf5\"))\n",
    "tdg = data_generator(train_files)\n",
    "vdg = data_generator(valid_files, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems\n",
    "\n",
    "#### OOM\n",
    "At the begining, the model is too large to train. Everytime I got OOM even at G initialization training. So I did some search and made some changes. Now the model is running.\n",
    "1. I add another GPU (MSI GTX 1070 8GB), which brings more memory in. This could be the most important change. Actually, not just GPU, I changed PSU (850W) as well to give more power supply to make two GPU running.\n",
    "1. With an extra GPU, I moved VGG network to /device:gpu:1, which will not be trained but consumes lots of memory. Because some weired DINT loading to GPU problem in tensorflow (or keras), G and D have to sit in the same GPU to avoid data loading/unloading from GPU. Cannot fix that, so I can only move VGG.\n",
    "1. Use `allow_growth`. Tensorflow always tries to allocate maximum memory it needs before actually running forward or backward according to my understading. But it can be changed by changing this parameter to `True`, which, in my case, saved some memory. https://github.com/keras-team/keras/issues/4161\n",
    "1. Reduce input size from 96x96 to 48x48. This helps a lot.\n",
    "#### Trainable warning\n",
    "\n",
    "Another problem is this anonying warning:\n",
    "\n",
    "`Warning: Discrepancy between trainable weights and collected trainable weights, did you set 'model.trainable' without calling 'model.compile' after ?`\n",
    "\n",
    "Looks like it is popular in the implementation of GAN networks. Because D needs to be frozn when training GAN, then open for training, and toggle between two status in each batch.\n",
    "\n",
    "Solution will be using tensorflow.python.keras.engine.network.Network to wrap D network, as a frozen model, which will not be updated during training, but weights gets updated when origin network been trained. Detail is in here: https://github.com/keras-team/keras/issues/8585\n",
    "\n",
    "#### Negative loss\n",
    "\n",
    "Loss function used by G and D were wrong, G was bin_crossentrophy, D was using mse. Swap them fixed the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 729s 146ms/step - loss: 0.0454 - val_loss: 0.0302\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 693s 139ms/step - loss: 0.0242 - val_loss: 0.0261\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 702s 140ms/step - loss: 0.0253 - val_loss: 0.0212\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 769s 154ms/step - loss: 0.0245 - val_loss: 0.0247\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 763s 153ms/step - loss: 0.0212 - val_loss: 0.0280\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 735s 147ms/step - loss: 0.0243 - val_loss: 0.0235\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 703s 141ms/step - loss: 0.0221 - val_loss: 0.0227\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 697s 139ms/step - loss: 0.0218 - val_loss: 0.0627\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 707s 141ms/step - loss: 0.0240 - val_loss: 0.0182\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 692s 138ms/step - loss: 0.0203 - val_loss: 0.0256\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 696s 139ms/step - loss: 0.0224 - val_loss: 0.0199\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 707s 141ms/step - loss: 0.0237 - val_loss: 0.0184\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 697s 139ms/step - loss: 0.0194 - val_loss: 0.0238\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 699s 140ms/step - loss: 0.0230 - val_loss: 0.0239\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 697s 139ms/step - loss: 0.0219 - val_loss: 0.0296\n",
      "Epoch 16/100\n",
      "5000/5000 [==============================] - 693s 139ms/step - loss: 0.0202 - val_loss: 0.0274\n",
      "Epoch 17/100\n",
      "5000/5000 [==============================] - 699s 140ms/step - loss: 0.0227 - val_loss: 0.0237\n",
      "Epoch 18/100\n",
      "5000/5000 [==============================] - 688s 138ms/step - loss: 0.0207 - val_loss: 0.0299\n",
      "Epoch 19/100\n",
      "5000/5000 [==============================] - 692s 138ms/step - loss: 0.0212 - val_loss: 0.0207\n",
      "Epoch 20/100\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 0.0233\n",
      "Epoch 00020: saving model to checkpoints/srgan/weights.020.hdf5\n",
      "5000/5000 [==============================] - 707s 141ms/step - loss: 0.0233 - val_loss: 0.0163\n",
      "Epoch 21/100\n",
      "5000/5000 [==============================] - 679s 136ms/step - loss: 0.0196 - val_loss: 0.0293\n",
      "Epoch 22/100\n",
      "5000/5000 [==============================] - 761s 152ms/step - loss: 0.0216 - val_loss: 0.0160\n",
      "Epoch 23/100\n",
      "5000/5000 [==============================] - 762s 152ms/step - loss: 0.0223 - val_loss: 0.0150\n",
      "Epoch 24/100\n",
      "5000/5000 [==============================] - 759s 152ms/step - loss: 0.0197 - val_loss: 0.0210\n",
      "Epoch 25/100\n",
      "5000/5000 [==============================] - 760s 152ms/step - loss: 0.0228 - val_loss: 0.0215\n",
      "Epoch 26/100\n",
      " 569/5000 [==>...........................] - ETA: 10:47 - loss: 0.0185"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6078634f95ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m                                              verbose=1, period=20)\n\u001b[0;32m     33\u001b[0m history = srgan.generator.fit_generator(tdg, steps_per_epoch=steps_per_epoch, validation_data=vdg,\n\u001b[1;32m---> 34\u001b[1;33m                                         validation_steps=5, epochs=num_epoch_init_g, callbacks=[checkpoint])\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mtraining_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\stephen\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2063\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2064\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2065\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   2066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2067\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mc:\\users\\stephen\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         outs = model.train_on_batch(\n\u001b[1;32m--> 171\u001b[1;33m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\stephen\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1827\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1828\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1830\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\stephen\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2977\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2978\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2979\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2980\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\stephen\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set allow_growth\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "# initialize tensorboard\n",
    "#tensorboard = keras.callbacks.TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "# DEFINE MODEL\n",
    "srgan = SRGAN(lr_height, lr_width, upscaling_factor=upscaling_rate)\n",
    "\n",
    "#print(srgan.generator.summary())\n",
    "#print(srgan.discriminator.summary())\n",
    "\n",
    "# Load previous training result\n",
    "saved_model_path = os.path.join(checkpoint_dir, \"trained\")\n",
    "if os.path.isfile(saved_model_path + \"_0_generator.h5\") and os.path.isfile(saved_model_path + \"_0_discriminator.h5\"):\n",
    "    srgan.load_weights(saved_model_path + \"_0_generator.h5\", saved_model_path + \"_0_discriminator.h5\")\n",
    "\n",
    "\n",
    "# Shape of output from discriminator\n",
    "#d_output_shape = list(srgan.discriminator.output_shape)\n",
    "#d_output_shape[0] = batch_size\n",
    "\n",
    "# VALID / FAKE targets for discriminator\n",
    "#real = tf.ones(d_output_shape)\n",
    "#fake = tf.zeros(d_output_shape)\n",
    "\n",
    "# initialize generator\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(os.path.join(checkpoint_dir, \"weights.{epoch:03d}.hdf5\"),\n",
    "                                             verbose=1, period=20)\n",
    "history = srgan.generator.fit_generator(tdg, steps_per_epoch=steps_per_epoch, validation_data=vdg,\n",
    "                                        validation_steps=5, epochs=num_epoch_init_g, callbacks=[checkpoint])\n",
    "\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(num_epoch_init_g, training_loss, 'r--')\n",
    "plt.plot(num_epoch_init_g, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();\n",
    "\n",
    "\n",
    "# save model\n",
    "#srgan.save_weights(os.path.join(checkpoint_dir, \"init\"))\n",
    "\n",
    "'''\n",
    "\n",
    "# train gan\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "bar = Progbar(steps_per_epoch)\n",
    "\n",
    "#print(srgan.discriminator.summary())\n",
    "\n",
    "for epoch in range(num_epoch_gan):\n",
    "    \n",
    "    print(\"Epoch %d/%d\" % (epoch+1, num_epoch_gan))\n",
    "\n",
    "    # batches\n",
    "    for i in range(steps_per_epoch):\n",
    "\n",
    "        (batch_lr, batch_hr) = next(tdg)\n",
    "\n",
    "        # train discriminator\n",
    "        generated_hr = srgan.generator.predict(batch_lr)\n",
    "\n",
    "        real_loss = srgan.discriminator.train_on_batch(batch_hr, real)\n",
    "        fake_loss = srgan.discriminator.train_on_batch(generated_hr, fake)\n",
    "        d_loss = np.add(real_loss, fake_loss)\n",
    "\n",
    "        # train generator\n",
    "        features_hr = srgan.vgg.predict(batch_hr)\n",
    "        g_loss = srgan.srgan.train_on_batch(batch_lr, [real, features_hr, batch_hr])\n",
    "        \n",
    "        # Save losses\n",
    "        g_losses.append(g_loss[0])\n",
    "        d_losses.append(d_loss[0])\n",
    "        \n",
    "        bar.update(i+1,\n",
    "                   [('d_loss', d_loss[0]),\n",
    "                    ('gan_loss', g_loss[0]),\n",
    "                    ('gan_d_loss', g_loss[1]),\n",
    "                    ('vgg_loss', g_loss[2]),\n",
    "                    ('g_loss', g_loss[3])])\n",
    "        \n",
    "    if epoch % checkpoint_step == 0:\n",
    "        srgan.save_weights(os.path.join(checkpoint_dir, \"trained_%d\" % epoch))\n",
    "\n",
    "\n",
    "# Save weights\n",
    "srgan.save_weights(os.path.join(checkpoint_dir, \"trained\"))\n",
    "\n",
    "# Plot g_lost\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(g_losses)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(d_losses)\n",
    "\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 384, 384, 3)\n",
      "(160, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load valid dataset\n",
    "data_filename = os.path.join(checkpoint_dir, \"valid.hdf5\")\n",
    "if os.path.isfile(data_filename):\n",
    "    hf = h5py.File(data_filename, 'r')\n",
    "    valid_hr = np.array(hf.get('valid_hr'))\n",
    "    valid_lr = np.array(hf.get('valid_lr'))\n",
    "    hf.close()\n",
    "else:\n",
    "    valid_hr, valid_lr = load_data(valid_hr_img_path, valid_lr_img_path)\n",
    "\n",
    "    # Save to disk\n",
    "    hf = h5py.File(data_filename, 'w')\n",
    "    hf.create_dataset('valid_hr', data=valid_hr)\n",
    "    hf.create_dataset('valid_lr', data=valid_lr)\n",
    "    hf.close()\n",
    "\n",
    "print(valid_hr.shape)\n",
    "print(valid_lr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model\n",
    "srgan = SRGAN()\n",
    "saved_model_path = os.path.join(checkpoint_dir, \"trained\")\n",
    "srgan.load_weights(saved_model_path + \"_generator.h5\", None)\n",
    "\n",
    "# Validation\n",
    "#valid_loss = srgan.generator.evaluate(valid_lr, valid_hr)\n",
    "\n",
    "#print(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 48, 48, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict(input_image):\n",
    "    \n",
    "    input_shape = input_image.shape\n",
    "    LR = np.zeros((0, lr_height, lr_width, 3))\n",
    "\n",
    "    for y in range(0, input_shape[0]-lr_height+1, lr_height):\n",
    "        y_end = y+lr_height\n",
    "        for x in range(0, input_shape[1]-lr_width+1, lr_width):\n",
    "            x_end = x+lr_width\n",
    "\n",
    "            lr_data = input_image[y:y_end, x:x_end, :]\n",
    "            if lr_data.shape[0] == lr_height and lr_data.shape[1] == lr_width:\n",
    "                LR = np.append(LR, np.expand_dims(lr_data, 0), axis=0)\n",
    "\n",
    "    print(LR.shape)\n",
    "    \n",
    "    output = srgan.generator.predict(LR)\n",
    "    r = upscaling_rate\n",
    "\n",
    "    output_image = np.zeros((input_shape[0]*r, input_shape[1]*r, output.shape[3]))\n",
    "    hr_width, hr_height = lr_width*r, lr_height*r\n",
    "    x, y = 0, 0\n",
    "    \n",
    "    x_max = output_image.shape[1]\n",
    "    for data in range(output.shape[0]):\n",
    "        x_end = x + hr_width\n",
    "        y_end = y + hr_height\n",
    "        output_image[y:y_end, x:x_end, :] = output[data]\n",
    "        x += hr_width\n",
    "        if x+hr_width >= x_max:\n",
    "            x = 0\n",
    "            y += hr_height\n",
    "\n",
    "    return output_image\n",
    "\n",
    "\n",
    "result = predict(plt.imread(os.path.join(valid_lr_img_path, \"0801x4.png\")))\n",
    "\n",
    "# Plot g_lost\n",
    "#print(result)\n",
    "plt.imsave(os.path.join(sample_dir, \"0801.png\"), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
